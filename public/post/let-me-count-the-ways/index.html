<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>let me count the ways</title>
<meta name="description" content="R notes to myself">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" href="http://jenrichmond.rbind.io/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="http://jenrichmond.rbind.io/css/font-awesome.min.css">
<link rel="stylesheet" href="http://jenrichmond.rbind.io/css/owl.carousel.css">
<link rel="stylesheet" href="http://jenrichmond.rbind.io/css/owl.theme.css">


  <link href="http://jenrichmond.rbind.io/css/style.default.css" rel="stylesheet" id="theme-stylesheet">

 

  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


<link href="http://jenrichmond.rbind.io/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="http://jenrichmond.rbind.io/img/favicon.png">


</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="http://jenrichmond.rbind.io/">R notes to myself</a></h1>
    
      <p class="sidebar-p">I am an academic @ UNSW Sydney, mother, and juggler. Learning new things and writing about it. Thoughts probably not suitable for public consumption.</p>
    
    <ul class="sidebar-menu">
      
      
        <li><a href="http://jenrichmond.rbind.io/about/">About</a></li>
      
        <li><a href="http://jenrichmond.rbind.io/post/">Blog</a></li>
      
        <li><a href="http://jenrichmond.rbind.io/contact/">Get in touch</a></li>
      
    </ul>
    <p class="social">
  
  
  
  <a href="https://twitter.com/JenRichmondPhD" data-animate-hover="pulse" class="external twitter">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  <a href="mailto:jrichmond@psy.unsw.edu.au" data-animate-hover="pulse" class="email">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  
  
  <a href="https://github.com/jenrichmond" data-animate-hover="pulse" class="external">
    <i class="fa fa-github"></i>
  </a>
  
  
</p>


    <div class="copyright">
      <p class="credit">
        
          &copy;2018 Jenny Richmond PhD
        
        | Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="http://jenrichmond.rbind.io/">R notes to myself</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>let me count the ways</h1>
         

<div id="TOC">
<ul>
<li><a href="#psycho-package"><code>psycho</code> package</a><ul>
<li><a href="#anova-recap">ANOVA Recap</a></li>
<li><a href="#emg-psycho">EMG + psycho</a></li>
<li><a href="#psycho-steps">psycho steps</a></li>
<li><a href="#thoughts-about-psycho">THOUGHTS about psycho</a></li>
</ul></li>
<li><a href="#likelihood-ratio-tests">Likelihood Ratio Tests</a><ul>
<li><a href="#lets-go-hiking">Lets go hiking</a></li>
<li><a href="#emg-lrt">EMG + LRT</a></li>
<li><a href="#thoughts-about-lrt">THOUGHTS about LRT</a></li>
</ul></li>
<li><a href="#lmertest-package"><code>lmerTest</code> package</a><ul>
<li><a href="#is-lrt-anticonservative">is LRT anticonservative?</a></li>
<li><a href="#emg-lmertest">EMG + lmerTest</a></li>
<li><a href="#thoughts-about-lmertest">THOUGHTS about lmerTest</a></li>
</ul></li>
<li><a href="#next-how-to-write-about-lmm">Next: “how to write about LMM”</a></li>
</ul>
</div>

<p>When we want to learn how to do something new in R, we all start by googling it. Having worked out simple ANOVA, next on my list is repeated measures.</p>
<p><a href="https://dominiquemakowski.github.io/">Domnique Makowski</a> has an excellent blog post that comes up at the top of the search results when you google “how to do repeated measures ANOVA in R”.</p>
<p>He lures you in with a <a href="https://neuropsychology.github.io/psycho.R/2018/05/01/repeated_measure_anovas.html">post that seems like it is going to solve all your problems</a> and then and BAM… starts the post by saying “DON’T do it”.</p>
<p>HAHAHAHAHA- got me….</p>
<div id="psycho-package" class="section level2">
<h2><code>psycho</code> package</h2>
<p>Yes I know that I should be doing linear mixed models instead, so lets see whether his <code>psycho</code> package really makes it as easy as promised.</p>
<pre class="r"><code>library(lme4)
library(lmerTest)
library(tidyverse)
library(psycho)</code></pre>
<div id="anova-recap" class="section level3">
<h3>ANOVA Recap</h3>
<div id="one-way-anova" class="section level4">
<h4>One-way ANOVA</h4>
<p>When we were talking one-way ANOVA we used this formula.</p>
<pre><code>aov(outcome ~ group, data = dataset)</code></pre>
</div>
<div id="old-school-repeated-measures-anova" class="section level4">
<h4>Old school: Repeated-measures ANOVA</h4>
<p>When participants contribute to all levels of condition, we need to describe that in the error term. Here the format of the aov call hasn’t changed much.</p>
<pre><code>aov(outcome ~ condition + Error(Participant/condition), 
    data= dataset)</code></pre>
</div>
<div id="new-school-linear-mixed-models" class="section level4">
<h4>New school: Linear mixed models</h4>
<p>The only difference between RM anova and linear mixed models is that you call <code>lmer</code> from the <code>lme4</code> package, instead of <code>aov</code> and specify a random effect of Participant (1|Participant) instead of the error term.</p>
<pre><code>lmer(outcome ~ condition + (1|Participant), 
    data= dataset)
</code></pre>
</div>
<div id="example-rapid-facial-mimicry" class="section level4">
<h4>Example: Rapid facial mimicry</h4>
<p>When we see someone smile, the muscles in our cheek that would produce a smile contract a tiny little bit. When we see someone display an angry expression, the muscles in our brow activate too.</p>
<p>This mimicry response is really robust in adults, but working out under what conditions it occurs in kids has kept me busy for a few years. This year my honours student Bronte is looking at how social context (i.e. competition vs cooperation) influences how kids mimic facial expressions of emotion.</p>
<p>In this experiment, we have participants watching pictures of different expressions (happy, angry) and we are recording activity from different muscle sites (brow, cheek). We are also showing kids pictures of confederates that they cooperated with, competed against, along with novel faces. In each condition (cooperator, competitor, novel), we want to determine whether the muscle activity differs as a function of emotional expression.</p>
<p>The advantage of LMM, in addition to allowing us to control for random effects of Participant, is that it doesn’t require that we have perfectly complete data, which is handy because… kids.</p>
<p>Lets plot responses to the competitor displaying happy vs. angry expressions.</p>
<pre class="r"><code>EMGdata &lt;- read_csv(&quot;BronteEMG.csv&quot;)

EMGdata_competitor &lt;- EMGdata %&gt;%
  filter(role == &quot;Competitor&quot;, emotion != &quot;NEUTRAL&quot;) </code></pre>
<pre class="r"><code>EMGdata_competitor %&gt;%
  group_by(emotion, muscle) %&gt;%
  summarise(meanresponse = mean(response, na.rm = TRUE)) %&gt;%
  ggplot(aes(x = emotion, y= meanresponse, fill = emotion)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;, width = 0.8) +
  facet_wrap(~muscle) +
  scale_y_continuous(expand = c(0, 0),                    
                     limits = c(-0.05, 0.25))</code></pre>
<p><img src="/post/2018-09-24-let-me-count-the-ways_files/figure-html/unnamed-chunk-3-1.png" width="672" /> Looks like a emotion x muscle interaction :)</p>
</div>
<div id="new-way-linear-mixed-models" class="section level4">
<h4>New way: Linear Mixed Models</h4>
<p>The code to run LMM is almost the same as aov; here we are still testing how well we can predict the response (outcome) from emotion and muscle , but now these are called “fixed effects”. And instead of specifying the Error term to account for the within subjects nature of the data, we can add Participant to the model as a “random effect”.</p>
<p>Instead of calling aov(), we now use lmer() from the lme4 package. Again we assign the model to an object, but this time run an anova() on the object.</p>
</div>
<div id="fit-the-model" class="section level4">
<h4>Fit the model</h4>
<pre class="r"><code>lmm_EMG &lt;- lmer(response ~ emotion + muscle + emotion*muscle + (1|Participant), data=EMGdata_competitor)

anova(lmm_EMG)</code></pre>
<pre><code>## Type III Analysis of Variance Table with Satterthwaite&#39;s method
##                 Sum Sq Mean Sq NumDF  DenDF F value  Pr(&gt;F)  
## emotion        0.23791 0.23791     1 79.159  3.3608 0.07053 .
## muscle         0.10038 0.10038     1 75.082  1.4180 0.23748  
## emotion:muscle 0.27447 0.27447     1 75.082  3.8772 0.05264 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
<div id="emg-psycho" class="section level3">
<h3>EMG + psycho</h3>
<div id="the-analyze-function" class="section level4">
<h4>The <code>analyze</code> function</h4>
<p>The <code>psycho</code> package allows you to test the fit of the model and generates a description of the results using an <code>analyze</code> and then <code>summary</code> and <code>print</code> functions.</p>
<pre class="r"><code>library(psycho)
results &lt;- analyze(lmm_EMG)</code></pre>
<pre><code>## Warning: &#39;r.squaredGLMM&#39; now calculates a revised statistic. See the help
## page.</code></pre>
<pre class="r"><code>summary(results)</code></pre>
<pre><code>##                                          Variable       Coef         SE
## (Intercept)                           (Intercept)  0.1919177 0.05627950
## emotionHAPPY                         emotionHAPPY -0.1973593 0.07341657
## muscleCHEEK                           muscleCHEEK -0.1633468 0.07241334
## emotionHAPPY:muscleCHEEK emotionHAPPY:muscleCHEEK  0.2035775 0.10338793
##                                  t       df           p   Coef_std
## (Intercept)               3.410081 94.48281 0.000956721  0.4364963
## emotionHAPPY             -2.688211 77.13899 0.008797648 -0.6620162
## muscleCHEEK              -2.255755 75.08189 0.026998252 -0.5479257
## emotionHAPPY:muscleCHEEK  1.969064 75.08189 0.052636001  0.6828745
##                             SE_std Effect_Size     CI_lower   CI_higher
## (Intercept)              0.1887823        &lt;NA&gt;  0.082725149  0.30144809
## emotionHAPPY             0.2462664      medium -0.339908396 -0.05402995
## muscleCHEEK              0.2429012      medium -0.304286200 -0.02240735
## emotionHAPPY:muscleCHEEK 0.3468015      medium  0.002351645  0.40480333</code></pre>
<p>This LMM practically writes itself! Use print(results) to generate an almost manuscript ready description of the model.</p>
<pre class="r"><code>print(results)</code></pre>
<pre><code>## The overall model predicting response (formula = response ~ emotion + muscle + emotion * muscle + (1 | Participant)) has an total explanatory power (conditional R2) of 22.73%, in which the fixed effects explain 6.48% of the variance (marginal R2). The model&#39;s intercept is at 0.19 (SE = 0.056, 95% CI [0.083, 0.30]). Within this model:
##    - The effect of emotionHAPPY is significant (beta = -0.20, SE = 0.073, 95% CI [-0.34, -0.054], t(77) = -2.69, p &lt; .01) and can be considered as medium (std. beta = -0.66, std. SE = 0.25).
##    - The effect of muscleCHEEK is significant (beta = -0.16, SE = 0.072, 95% CI [-0.30, -0.022], t(75) = -2.26, p &lt; .05) and can be considered as medium (std. beta = -0.55, std. SE = 0.24).
##    - The effect of emotionHAPPY:muscleCHEEK is significant (beta = 0.20, SE = 0.10, 95% CI [0.0024, 0.40], t(75) = 1.97, p = 0.05�) and can be considered as medium (std. beta = 0.68, std. SE = 0.35).</code></pre>
<p>Here we are most interested in the interaction, so we can use <code>get_contrasts</code> for the interaction term, add them to the results and print them too.</p>
</div>
<div id="get_contrasts" class="section level4">
<h4><code>get_contrasts</code></h4>
<pre class="r"><code>results &lt;- get_contrasts(lmm_EMG, &quot;emotion*muscle&quot;)
print(results$contrasts)</code></pre>
<pre><code>##                    Contrast   Difference         SE       df     t.ratio
## 1   ANGRY,BROW - HAPPY,BROW  0.197359266 0.07348138 77.39796  2.68584041
## 2  ANGRY,BROW - ANGRY,CHEEK  0.163346775 0.07241334 75.35489  2.25575531
## 3  ANGRY,BROW - HAPPY,CHEEK  0.157128552 0.07348138 77.39796  2.13834508
## 4  HAPPY,BROW - ANGRY,CHEEK -0.034012491 0.07348138 77.39796 -0.46287222
## 5  HAPPY,BROW - HAPPY,CHEEK -0.040230714 0.07379277 75.35489 -0.54518507
## 6 ANGRY,CHEEK - HAPPY,CHEEK -0.006218223 0.07348138 77.39796 -0.08462311
##      p.value
## 1 0.04301329
## 2 0.11787330
## 3 0.15022769
## 4 0.96688804
## 5 0.94756741
## 6 0.99978085</code></pre>
<pre class="r"><code>#note default is Tukey correction</code></pre>
<pre class="r"><code>print(results$means) #get estimated marginal means</code></pre>
<pre><code>##   emotion muscle         Mean         SE       df    CI_lower CI_higher
## 1   ANGRY   BROW  0.191917672 0.05630582 94.57849  0.08013007 0.3037053
## 2   HAPPY   BROW -0.005441594 0.05735259 95.27434 -0.11929665 0.1084135
## 3   ANGRY  CHEEK  0.028570897 0.05630582 94.57849 -0.08321671 0.1403585
## 4   HAPPY  CHEEK  0.034789120 0.05735259 95.27434 -0.07906594 0.1486442</code></pre>
</div>
</div>
<div id="psycho-steps" class="section level3">
<h3>psycho steps</h3>
<ol style="list-style-type: decimal">
<li><p>define the model and and run it</p>
<p>model &lt;- lmer(outcome ~ fixed_effects + (1|random_effect), data=dataset)</p></li>
</ol>
<p>2a. then anova(model)</p>
<p>2b. OR summary(model)</p>
<ol start="3" style="list-style-type: decimal">
<li><p>to get user friendly descriptions you can plug into other things use results &lt;- analyze(model)</p></li>
<li><p>to get all info you might want to report (both ANOVA and regression format) ask for summary(results)</p></li>
<li><p>to get manuscript ready descriptions use ask for print(results)</p></li>
<li><p>to work out interactions get_contrasts(model)</p></li>
</ol>
</div>
<div id="thoughts-about-psycho" class="section level3">
<h3>THOUGHTS about psycho</h3>
<ul>
<li>there are a lot of steps</li>
<li>do I really need all of this output?</li>
<li>how do I write about this?</li>
</ul>
</div>
</div>
<div id="likelihood-ratio-tests" class="section level2">
<h2>Likelihood Ratio Tests</h2>
<p>The psycho package relies on the <code>lmerTest</code> package to generate p values, which in “Linear Mixed Model Land” are controversial. The alternative approach is to apply Likelihood Ratio Tests. This procedure involves running a model with ALL of your interesting fixed effects in it, then running a model that removes the fixed effects you are most interested in. By comparing the “fit” of model 1 vs. model 2 you can get an idea of whether the variable of interest is important.</p>
<p>Bodo Winter has a <a href="tutorialhttp://www.bodowinter.com/tutorials.html">great two part</a> that lays out the logic of this nicely. He uses a hiking analogy that I found really useful in getting my head around the idea of Likelihood Ratio Tests.</p>
<div id="lets-go-hiking" class="section level3">
<h3>Lets go hiking</h3>
<p>Imagine we were interested in predicting hiking speed and we wanted to know whether carrying water and/or carrying a flashlight impacts the speed that we walk.</p>
<p>To test the effect of water, we could run model 1, which includes fixed effects of both water and flashlight, and model 2, which removes the effect of water. Then we could compare model 1 and model 2. If model 1 fits the data better (as evidenced by a <em>lower</em> AIC value), we can say that carrying water slows us down.</p>
<p>model1 = hiking speed ~ gallon of water + flashlight</p>
<p>model2 = hiking speed ~ flashlight</p>
</div>
<div id="emg-lrt" class="section level3">
<h3>EMG + LRT</h3>
<p>Using this approach with our EMG data would involve fitting a model with both main effects (emotion and muscle) AND the interaction between emotion * muscle included.</p>
<p>Because we are most interested in whether there is a differential muscle activity in response to each emotion (i.e. is cheek activity greater for happy than angry faces and brow activity greater for angry then happy), our comparison model would remove the interation term.</p>
<p>Note when you are running LMM and planning to compare models, you should add REML= FALSE to the end of the code. Changes the internal workings in mysterious ways.</p>
<pre class="r"><code>model_target &lt;- lmer(response ~ emotion + muscle + emotion*muscle + (1|Participant), data=EMGdata_competitor, REML= FALSE)</code></pre>
<pre class="r"><code>model_null &lt;- lmer(response ~ emotion + muscle + (1|Participant), data=EMGdata_competitor, REML= FALSE)</code></pre>
<pre class="r"><code>anova(model_null, model_target)</code></pre>
<pre><code>## Data: EMGdata_competitor
## Models:
## model_null: response ~ emotion + muscle + (1 | Participant)
## model_target: response ~ emotion + muscle + emotion * muscle + (1 | Participant)
##              Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)  
## model_null    5 46.288 59.605 -18.144   36.288                           
## model_target  6 44.358 60.339 -16.179   32.358 3.9295      1    0.04745 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Interpretation= when the AIC (Akaike information criterion) is lower, the model fits the data better. Here we can say that the emotion * muscle interaction is important, because there the model_target is a better fit of the data than model_null is.</p>
</div>
<div id="thoughts-about-lrt" class="section level3">
<h3>THOUGHTS about LRT</h3>
<ul>
<li>this is way simpler and more intuitive than psycho</li>
<li>but I feel like I need something else</li>
<li>it doesn’t seem enough to only know that the interaction is important</li>
<li>how do I write about this?</li>
</ul>
</div>
</div>
<div id="lmertest-package" class="section level2">
<h2><code>lmerTest</code> package</h2>
<p>As mentioned above, significance testing in LMM is controversial. The authors of the <code>lme4</code> package didn’t include p values in the model output, because they argue that there is no way to estimate degrees of freedom. I don’t pretend to have a full grasp on the statistical intricacies, but the <a href="https://www.jstatsoft.org/article/view/v082i13">paper that goes with the <code>lmerTest</code> package</a> is worth a read.</p>
<div id="is-lrt-anticonservative" class="section level3">
<h3>is LRT anticonservative?</h3>
<p>In this paper, the authors argue that of course researchers using LMM want some indication of the significance of their effect but that a LRT approach is anti-conservative. They designed the <code>lmerTest</code> package to provide an alternative.</p>
<p>The <code>lmerTest</code> approach uses Satterthwaite’s method (as does SAS software) to estimate degrees of freedom and make it possible for both anova() and summary() functions on lmer objects to include p values.</p>
<p>This example illustrates the difference in output when you run anova() on model before and after loading library(lmerTest)</p>
<div class="figure">
<img src="/post/2018-09-24-let-me-count-the-ways_files/lmerTest.jpg" />

</div>
</div>
<div id="emg-lmertest" class="section level3">
<h3>EMG + lmerTest</h3>
<p>Using the lmerTest approach, we would load library(lmerTest) first, then run the model including all interesting fixed and random effects. Then call anova() and/or summary() to get Fs and ps and/or Estimates.</p>
<pre class="r"><code>library(lmerTest)

model_lmerTest &lt;- lmer(response ~ emotion + muscle + emotion*muscle + (1|Participant), data=EMGdata_competitor)</code></pre>
<p>Then get anova() and/or summary() to get Fs and Ps, and beta estimates.</p>
<pre class="r"><code>anova(model_lmerTest)</code></pre>
<pre><code>## Type III Analysis of Variance Table with Satterthwaite&#39;s method
##                 Sum Sq Mean Sq NumDF  DenDF F value  Pr(&gt;F)  
## emotion        0.23791 0.23791     1 79.159  3.3608 0.07053 .
## muscle         0.10038 0.10038     1 75.082  1.4180 0.23748  
## emotion:muscle 0.27447 0.27447     1 75.082  3.8772 0.05264 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(model_lmerTest)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: 
## response ~ emotion + muscle + emotion * muscle + (1 | Participant)
##    Data: EMGdata_competitor
## 
## REML criterion at convergence: 48.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.86009 -0.40051 -0.01831  0.37171  2.89182 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  Participant (Intercept) 0.01489  0.1220  
##  Residual                0.07079  0.2661  
## Number of obs: 106, groups:  Participant, 28
## 
## Fixed effects:
##                          Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)               0.19192    0.05628 94.48281   3.410 0.000957 ***
## emotionHAPPY             -0.19736    0.07342 77.13899  -2.688 0.008798 ** 
## muscleCHEEK              -0.16335    0.07241 75.08189  -2.256 0.026998 *  
## emotionHAPPY:muscleCHEEK  0.20358    0.10339 75.08189   1.969 0.052636 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) emHAPPY mCHEEK
## emotinHAPPY -0.638               
## muscleCHEEK -0.643  0.493        
## eHAPPY:CHEE  0.451 -0.704  -0.700</code></pre>
</div>
<div id="thoughts-about-lmertest" class="section level3">
<h3>THOUGHTS about lmerTest</h3>
<ul>
<li>this approach seems the most like repeated measures ANOVA</li>
<li>I still don’t really know how to write about this</li>
</ul>
</div>
</div>
<div id="next-how-to-write-about-lmm" class="section level2">
<h2>Next: “how to write about LMM”</h2>
</div>

         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="http://jenrichmond.rbind.io/js/jquery.min.js"></script>
<script src="http://jenrichmond.rbind.io/js/bootstrap.min.js"></script>
<script src="http://jenrichmond.rbind.io/js/jquery.cookie.js"> </script>
<script src="http://jenrichmond.rbind.io/js/ekko-lightbox.js"></script>
<script src="http://jenrichmond.rbind.io/js/jquery.scrollTo.min.js"></script>
<script src="http://jenrichmond.rbind.io/js/masonry.pkgd.min.js"></script>
<script src="http://jenrichmond.rbind.io/js/imagesloaded.pkgd.min.js"></script>
<script src="http://jenrichmond.rbind.io/js/owl.carousel.min.js"></script>
<script src="http://jenrichmond.rbind.io/js/front.js"></script>

</body>
</html>
