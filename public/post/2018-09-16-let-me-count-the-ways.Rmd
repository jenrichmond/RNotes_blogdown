---
title: let me count the ways
author: ''
date: '2018-09-16'
slug: let-me-count-the-ways
categories: []
output:
  blogdown::html_page:
    toc: true
tags:
  - analysis
  - lmm
  - repeated measures
---

When you want to learn how to do something new in R, we all start by googling it. Having worked out simple ANOVA, next on my list is repeated measures.  

[Domnique Makowski](https://dominiquemakowski.github.io/) has an excellent blog post that comes up at the top of the search results when you type "how to do repeated measures ANOVA in R" into google.

![](/post/2018-09-16-let-me-count-the-ways_files/google.png)

He lures you in with a [post that seems like it is going to solve all your problems](https://neuropsychology.github.io/psycho.R/2018/05/01/repeated_measure_anovas.html) and then and BAM... starts the post by saying DON'T do it. 

HAHAHAHAHA- got me....

## 1. `psycho` package

Yes I know that I should be doing linear mixed models instead, so lets see whether his `psycho` package really makes it as easy as promised. 

```{r message=FALSE, warning=FALSE}
library(psycho)
library(lmerTest)

emotiondata <- emotion
```

### Recap

#### One way ANOVA
When we were talking one-way ANOVA we used this formula. 

```
aov(outcome ~ group, data = dataset)
```

#### Repeated measures ANOVA
Now that participants contribute to all levels of condition, we need to specify that in the error term. Here the format of the aov call hasn't changed much.
```
aov(outcome ~ condition + Error(Participant/condition), data= dataset)

```
#### Linear mixed models

The only difference between RM anova and linear mixed models is that you called `lmer` instead of `aov` and specify a random effet of Participant (1|Participant) instead of the error term. 

```
lmer(outcome ~ condition + (1|Participant), data= dataset)

```

### A psycho example 
Lets imagine we had participants rating the valence of pictures and we wanted to see if there was a difference in the valence ratings for ones that were considered negative vs. neutral. It is a good idea to assign the aov to an object so we can ask for summary or print. 

### Old way: repeated-measures ANOVA
```{r}
RM_anova <- aov(Subjective_Valence ~ Emotion_Condition +
                  Error(Participant_ID/Emotion_Condition),           data=emotiondata)

summary(RM_anova)
# print(RM_anova)
```
The summary() gives you enough information to write about it in your results, and print() gives extra details about sums of squares etc.  

### New way: Linear mixed models
Alternatively we can analyse the data using Linear Mixed Models. The code is almost the same, we are still looking at whether valence ratings (outcome) are influenced by emotion condition, but now this is called a "fixed effect".  And instead of specifying the Error term to account for the within subjects nature of the data, we can add Participant to the model as a "random effect". 

Instead of calling aov(), we now use lmer(). Again we assign the model to an object, but this time run an anova() on the object. 

#### Fit the model
```{r}
library(lmerTest)

lmm_emotion <- lmer(Subjective_Valence ~ Emotion_Condition + (1|Participant_ID), data=emotiondata)

anova(lmm_emotion)
```
The LMM output is really similarly structured (the sums of squares value is exactly the same) and just like repeated measures ANOVA shows a significant effect of Emotion Condition on valence ratings. 

The `psycho` package also allows you to test the fit of the model and generates a description of the results using an `analyze` and then `print` function. 

#### The `analyze` function

This LMM practically writes itself! Use print(results) to generate an almost manuscript ready description of the model. 

```{r}
results1 <- analyze(lmm_emotion)

print(results1)

```

It would be nice to know, which way that Emotion effect went. Next step in the `psycho` process is to run contrasts;  you use `get_contrasts`,  add them to the results and print them too.  

#### `get_contrasts`
```{r}

results1 <- get_contrasts(lmm_emotion, "Emotion_Condition")
print(results1$contrasts)
```

What if there were two fixed effects? In this model, we add sex as an additional predictor. As in one way anova, by specifying Emotion * Sex, you are really saying we want main effects of emotion, sex, and the interaction. 

#### A more complex model w interaction
```{r}
lmm_emotion_sex <- lmer(Subjective_Valence ~ Emotion_Condition * Participant_Sex + (1|Participant_ID), data=emotiondata)

anova(lmm_emotion_sex)
```

```{r}
results2 <- get_contrasts(lmm_emotion_sex, "Emotion_Condition * Participant_Sex") 

#note this by default uses Tukey correction

print(results2$means) #get estimated marginal means
```

```{r}
print(results2$contrasts)
```
Default on get_contrasts is Tukey correction, below with adjustment for multiple comparisons removed. 
```{r}
results2 <- get_contrasts(lmm_emotion_sex, "Emotion_Condition * Participant_Sex", adjust = "none")

print(results2$contrasts)
```

### Summary of `psycho` process

1. define the model and and run it

       model <- lmer(outcome ~ fixed_effects + (1|random_effect), data=dataset)
       
2A. then 

       anova(model)
       
2B. OR

       summary(model)
       
3. to get user friendly descriptions you can plug into other things use analyze

       results <- analyze(model) 
       
3. to get all info you might want to report (both ANOVA and regression format)

       summary(results)
       
4. to get manuscript ready descriptions use 

       print(results) 
       
4. to work out interactions 

       get_contrasts(model)
       
## 2. Bodo Winter tutorial







## 3. lmerTest tutorial (Per Bruum Brockhoff)
## 4. UWS course 


