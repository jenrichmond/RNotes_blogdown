---
title: a friendly t-test example
author: 'Jen Richmond'
date: '2018-09-08'
slug: a-friendly-t-test-example
categories: []
tags: 
- ttest
---



<p>This dataset is from the car package and includes recall scores as a function of encoding conditions.</p>
<pre class="r"><code>friendly &lt;- read.csv(&quot;friendly.csv&quot;)

class(friendly)</code></pre>
<pre><code>## [1] &quot;data.frame&quot;</code></pre>
<div id="explore-the-friendly-data" class="section level4">
<h4>Explore the friendly data</h4>
<p>Get some summary stats from <code>skim()</code> including mini-histograms</p>
<pre class="r"><code>skim(friendly)</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 30 
##  n variables: 2 
## 
## ── Variable type:factor ────────────────────────────────────────────
##   variable missing complete  n n_unique                       top_counts
##  condition       0       30 30        3 Bef: 10, Mes: 10, SFR: 10, NA: 0
##  ordered
##    FALSE
## 
## ── Variable type:integer ───────────────────────────────────────────
##  variable missing complete  n mean   sd p0 p25 p50 p75 p100     hist
##   correct       0       30 30 34.5 6.12 21  30  37  39   40 ▁▃▁▂▁▁▃▇</code></pre>
</div>
<div id="one-sample-t-test" class="section level4">
<h4>1. One-sample t-test</h4>
<p>Who knows what chance performance on this tasks is, but lets say 30. Is accuracy performance significantly above chance?</p>
<p>Using the function from <code>lsr</code> for this kind of test the command takes the form:</p>
<pre class="r"><code>oneSampleTTest(friendly$correct, mu=30)</code></pre>
<pre><code>## 
##    One sample t-test 
## 
## Data variable:   friendly$correct 
## 
## Descriptive statistics: 
##             correct
##    mean      34.500
##    std dev.   6.124
## 
## Hypotheses: 
##    null:        population mean equals 30 
##    alternative: population mean not equal to 30 
## 
## Test results: 
##    t-statistic:  4.025 
##    degrees of freedom:  29 
##    p-value:  &lt;.001 
## 
## Other information: 
##    two-sided 95% confidence interval:  [32.213, 36.787] 
##    estimated effect size (Cohen&#39;s d):  0.735</code></pre>
<p>Wow that is pretty nice output. Include descriptives, t-test results and useful information that you usually have to ask SPSS to do in an extra step.</p>
</div>
<div id="independent-sample-t-test" class="section level4">
<h4>2. Independent sample t-test</h4>
<p>OK so performance across the board is above “chance” but does it differ across condition? Of course, the skim() function above only gives descriptives across the board so lets use group_by to to get grouped summary stats and the ggplot to eyeball whether there might be differences by condition.</p>
<ol style="list-style-type: decimal">
<li>get summary stats by group</li>
</ol>
<pre class="r"><code>friendlygrouped &lt;- friendly %&gt;%
  group_by(condition) %&gt;%
  summarise(meanacc = mean(correct))
 
friendlygrouped</code></pre>
<pre><code>## # A tibble: 3 x 2
##   condition meanacc
##   &lt;fct&gt;       &lt;dbl&gt;
## 1 Before       36.6
## 2 Meshed       36.6
## 3 SFR          30.3</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>plot group differences in performance</li>
</ol>
<pre class="r"><code> friendlygrouped %&gt;%
 ggplot(aes(x= condition, y=meanacc)) +
  geom_col()</code></pre>
<p><img src="/projects/2018-09-10-a-friendly-t-test-example_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>It looks like there are interesting differences between Meshed and SFR.</p>
<p>Without participant numbers or IDs it is impossible know whether this experiment was between subjects or within subjects. I know it was about recall under different encoding conditions, but we don’t know whether all participants learned and recalled under all encoding conditions (within) or whether there were different groups of participants tested on each of the 3 conditions (between).</p>
<p>Lets assume that there are groups for now, and test whether there are differences in recall by condition using a independent samples t-test.</p>
<p>Our data has 3 groups, so lets create a new dataframe that only includes the SFR and Meshed condition</p>
<pre class="r"><code>justSFRmesh &lt;- friendly %&gt;%
  filter(condition != &quot;Before&quot;)</code></pre>
<p>The function for independent sample t-test specifies the outcome and grouping variable, the dataframe that the data is in, and an indication of whether the variance is expected to be equal.</p>
<p>Note R assumes variance in unequal and defaults to the Welch t-test, if you want Student t-test you need to specify var.equal = TRUE</p>
<p><strong>Welch t-test</strong></p>
<pre><code>independentSamplesTTest(
  formula = outcome ~ group, 
  data = dataframe, 
  var.equal = FALSE
)</code></pre>
<p><strong>Student t-test</strong></p>
<pre><code>independentSamplesTTest(
  formula = outcome ~ group, 
  data = dataframe, 
  var.equal = TRUE
)</code></pre>
<p>As with lots of R functions you can short cut it like this…</p>
<pre><code>independentSampleTTest(outcome ~ group, dataframe, TRUE)
</code></pre>
<pre class="r"><code>independentSamplesTTest(
  formula = correct ~ condition, 
  data = justSFRmesh,
  var.equal = TRUE
)</code></pre>
<pre><code>## Warning in independentSamplesTTest(formula = correct ~ condition, data =
## justSFRmesh, : grouping variable has unused factor levels</code></pre>
<pre><code>## 
##    Student&#39;s independent samples t-test 
## 
## Outcome variable:   correct 
## Grouping variable:  condition 
## 
## Descriptive statistics: 
##             Meshed    SFR
##    mean     36.600 30.300
##    std dev.  3.026  7.334
## 
## Hypotheses: 
##    null:        population means equal for both groups
##    alternative: different population means in each group
## 
## Test results: 
##    t-statistic:  2.511 
##    degrees of freedom:  18 
##    p-value:  0.022 
## 
## Other information: 
##    two-sided 95% confidence interval:  [1.029, 11.571] 
##    estimated effect size (Cohen&#39;s d):  1.123</code></pre>
</div>
<div id="paired-t-test" class="section level4">
<h4>3. Paired t-test</h4>
<p>It is possible that everyone in this experiment studied under all three conditions and that the data is in fact paired. The paired t-test function in <code>lsr</code> requires an ID, so lets pretend this was a within subjects experiment and create Participant 1-10</p>
<pre class="r"><code>friendlypaired &lt;- friendly %&gt;%
  mutate(Participant = rep(1:10, times = 3)) %&gt;%
 filter(condition != &quot;Before&quot;)</code></pre>
<pre class="r"><code>glimpse(friendlypaired)</code></pre>
<pre><code>## Observations: 20
## Variables: 3
## $ condition   &lt;fct&gt; SFR, SFR, SFR, SFR, SFR, SFR, SFR, SFR, SFR, SFR, ...
## $ correct     &lt;int&gt; 39, 25, 37, 25, 29, 39, 21, 39, 24, 25, 40, 39, 34...
## $ Participant &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7...</code></pre>
<pre class="r"><code>pairedSamplesTTest(
  formula = correct ~ condition, 
  data = friendlypaired, 
  id = &quot;Participant&quot;)</code></pre>
<pre><code>## Warning in pairedSamplesTTest(formula = correct ~ condition, data =
## friendlypaired, : grouping variable has unused factor levels</code></pre>
<pre><code>## Warning in pairedSamplesTTest(formula = correct ~ condition, data =
## friendlypaired, : id variable is not a factor</code></pre>
<pre><code>## 
##    Paired samples t-test 
## 
## Outcome variable:   correct 
## Grouping variable:  condition 
## ID variable:        Participant 
## 
## Descriptive statistics: 
##             Meshed    SFR difference
##    mean     30.300 36.600     -6.300
##    std dev.  7.334  3.026      7.288
## 
## Hypotheses: 
##    null:        population means equal for both measurements
##    alternative: different population means for each measurement
## 
## Test results: 
##    t-statistic:  -2.733 
##    degrees of freedom:  9 
##    p-value:  0.023 
## 
## Other information: 
##    two-sided 95% confidence interval:  [-11.514, -1.086] 
##    estimated effect size (Cohen&#39;s d):  0.864</code></pre>
</div>
